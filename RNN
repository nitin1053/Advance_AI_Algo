import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense

# Step 1: Load and Preprocess the Data
def load_and_preprocess_text(file_path, seq_length=100):
    with open(file_path, 'r', encoding='utf-8') as file:
        text = file.read()

    vocab = sorted(set(text))  # Unique characters
    char2idx = {char: idx for idx, char in enumerate(vocab)}
    idx2char = np.array(vocab)
    text_as_int = np.array([char2idx[char] for char in text])

    # Prepare input-output pairs
    char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)
    sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)

    dataset = sequences.map(lambda chunk: (chunk[:-1], chunk[1:]))
    return dataset, char2idx, idx2char, len(vocab)

file_path = "RNN 1.txt"  # Replace with your .txt file path
seq_length = 100
dataset, char2idx, idx2char, vocab_size = load_and_preprocess_text(file_path, seq_length)

# Batch and shuffle
BATCH_SIZE = 64
dataset = dataset.shuffle(10000).batch(BATCH_SIZE, drop_remainder=True)

# Step 2: Build the RNN Model
def build_rnn_model(vocab_size, embedding_dim=256, rnn_units=103):
    return Sequential([
        Embedding(vocab_size, embedding_dim),
        SimpleRNN(rnn_units, return_sequences=True),
        Dense(vocab_size)
    ])

model = build_rnn_model(vocab_size)
model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))

# Step 3: Train the Model
model.fit(dataset, epochs=20)

# Step 4: Generate Text
def generate_text(model, start_string, char2idx, idx2char, temperature=1.0, num_generate=1000):
    input_eval = [char2idx[char] for char in start_string]
    input_eval = tf.expand_dims(input_eval, 0)
    generated_text = []

    for _ in range(num_generate):
        predictions = model(input_eval)
        predictions = tf.squeeze(predictions, 0) / temperature
        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()
        input_eval = tf.expand_dims([predicted_id], 0)
        generated_text.append(idx2char[predicted_id])

    return start_string + ''.join(generated_text)

# Example: Generate text
start_string = "Once upon a time"
print(generate_text(model, start_string, char2idx, idx2char))
